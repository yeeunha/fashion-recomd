{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO_sgbsGkqjz",
        "outputId": "9f26409d-cd37-4ebe-bfc9-244b4674eeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "0fEDf2Q4OeoG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR7e3LJTUC5t"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.utils as utils\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lOQUBnhy003"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/K-Fashion/'\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "image_dataset =  datasets.ImageFolder(data_dir, data_transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = 0.7\n",
        "split_size = int(len(image_dataset) * train_split)\n",
        "batch_size = 16\n",
        "num_workers= 6"
      ],
      "metadata": {
        "id": "tCfLnQ53rDQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, valid_set = torch.utils.data.random_split(image_dataset, [split_size, len(image_dataset) - split_size])\n",
        "tr_loader = utils.data.DataLoader(dataset=train_set,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            num_workers=num_workers)\n",
        "val_loader = utils.data.DataLoader(dataset=valid_set,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=False,\n",
        "                              num_workers=num_workers)\n",
        "dataloaders = {'train': tr_loader, 'val':val_loader}\n",
        "dataset_sizes = {}\n",
        "dataset_sizes['train'] = split_size\n",
        "dataset_sizes['val'] = len(image_dataset) -split_size\n",
        "class_names = image_dataset.classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "EvF-zlHtO74K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ac6f3d-ac5d-4948-c91e-034e1a68e0dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=2):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "hQT0cXYfO_cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(image_dataset.classes))\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joPX4XFOW0A7",
        "outputId": "5670146b-0f29-4235-8e81-1b1a6df8a697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 291MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SESOfsB41VQH",
        "outputId": "2c7733c1-f7b5-4f48-e4e3-8a4eba6fd1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 2.6817 Acc: 0.2043\n",
            "val Loss: 2.6571 Acc: 0.2237\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 2.5517 Acc: 0.2402\n",
            "val Loss: 2.6154 Acc: 0.2140\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 2.4512 Acc: 0.2590\n",
            "val Loss: 2.5609 Acc: 0.2459\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 2.3596 Acc: 0.2994\n",
            "val Loss: 2.5536 Acc: 0.2551\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 2.2891 Acc: 0.3110\n",
            "val Loss: 2.6832 Acc: 0.2425\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 2.2261 Acc: 0.3333\n",
            "val Loss: 2.5584 Acc: 0.2647\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 2.1496 Acc: 0.3447\n"
          ]
        }
      ],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TEST"
      ],
      "metadata": {
        "id": "dKq0hQhSK-hz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqawKO1jCyUp"
      },
      "outputs": [],
      "source": [
        "class TestDataset(utils.data.Dataset):\n",
        "  def __init__(self, root, transform=None):\n",
        "    self.root = root\n",
        "    self.image_list = os.listdir(root)\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_path = os.path.join(self.root, self.image_list[index])\n",
        "    image = np.array(Image.open(image_path))\n",
        "    image = self.transform(image)\n",
        "    return self.image_list[index], image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT-AjSc3Cu_s"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "      transforms.ToPILImage(),\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/캐주얼/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/캐주얼_resived.csv')"
      ],
      "metadata": {
        "id": "QarUaDwqucmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/로맨틱/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/로맨틱_resived.csv')"
      ],
      "metadata": {
        "id": "lpOtEYyA8ESm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/유니크/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/유니크_resived.csv')"
      ],
      "metadata": {
        "id": "Yw1W9BmTJFNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/심플베이직/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/심플베이직_resived.csv')"
      ],
      "metadata": {
        "id": "MnxI_0NfJH1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/러블리/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/러블리_resived.csv')"
      ],
      "metadata": {
        "id": "yMeBZ_aCJKZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/캠퍼스룩/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/캠퍼스룩_resived.csv')"
      ],
      "metadata": {
        "id": "MWlSM2bMJMgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/오피스룩/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/오피스룩_resived.csv')"
      ],
      "metadata": {
        "id": "asStjDpGJRCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/빈티지/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/빈티지_resived.csv')"
      ],
      "metadata": {
        "id": "upWch0eAJSMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/모던시크/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/모던시크_revised.csv')"
      ],
      "metadata": {
        "id": "mWyqADchJUFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/컨템포러리/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/컨템포러리_revised.csv')"
      ],
      "metadata": {
        "id": "yAb4OoHFJVHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/클래식/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/클래식_revised.csv')"
      ],
      "metadata": {
        "id": "7YxCNoMIJZ99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/유니섹스/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/유니섹스_revised.csv')"
      ],
      "metadata": {
        "id": "nWj5GaszJddo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/럭셔리/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/럭셔리_revised.csv')"
      ],
      "metadata": {
        "id": "X00O-VsLNegf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/섹시글램/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/섹시글램_revised.csv')"
      ],
      "metadata": {
        "id": "9ohPAkqTNgbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/데청캠_공유/쇼핑몰/아메카지/\" # 스타일 입력\n",
        "mall = os.listdir(path) # 쇼핑몰 리스트\n",
        "result=[]\n",
        "for i in range(len(mall)):\n",
        "  path2 = path + mall[i]\n",
        "  test_dataset = TestDataset(path2,transform=test_transform)\n",
        "  test_dataloader = utils.data.DataLoader(test_dataset, batch_size=16, num_workers=16)\n",
        "  for fnames, data in tqdm(test_dataloader):\n",
        "    data = data.to(device)\n",
        "    output = model_ft(data)\n",
        "    _,pred = torch.max(output,1)\n",
        "    for j in range(len(fnames)):\n",
        "      result.append(\n",
        "          {'filename':fnames[j], 'mall':mall[i], 'style':pred.cpu().detach().numpy()[j]})\n",
        "\n",
        "df=pd.DataFrame(sorted(result,key=lambda x:x['filename']))\n",
        "sorted_df = df.sort_values(by='mall')\n",
        "sorted_df2 = sorted_df.reset_index(drop=True)\n",
        "sorted_df2.to_csv('/content/drive/MyDrive/데청캠_공유/쇼핑몰 라벨/아메카지_revised.csv')"
      ],
      "metadata": {
        "id": "3wyhJP3rPYhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sfM8ZrBIoiyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}